{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdbe98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87e05f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dell\\\\File_handling'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f03a45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empid,empname,empage,salary\n",
      "1,aaaa,21,20000\n",
      "2,bbbb,23,30000\n",
      "3,cccccc,24,400000\n",
      "4,dddd,25,50000\n",
      "5,eeeee,26,60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reading pdf file\n",
    "with open('emp.csv') as i:\n",
    "    f_read=i.read()\n",
    "    print(f_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed948937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empid', 'empname', 'empage', 'salary']\n",
      "['1', 'aaaa', '21', '20000']\n",
      "['2', 'bbbb', '23', '30000']\n",
      "['3', 'cccccc', '24', '400000']\n",
      "['4', 'dddd', '25', '50000']\n",
      "['5', 'eeeee', '26', '60000']\n"
     ]
    }
   ],
   "source": [
    "w= open('emp.csv')\n",
    "read=csv.reader(w)\n",
    "for i in read:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "efe2a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1', 'aaaa', '21', '20000'], ['2', 'bbbb', '23', '30000']]\n"
     ]
    }
   ],
   "source": [
    "# slicing\n",
    "w = open('emp.csv')\n",
    "read = csv.reader(w)\n",
    "slice = list(read)\n",
    "print(slice[1:3])\n",
    "\n",
    "  #or\n",
    "#for i in slice[:]:\n",
    " #   print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1178ed2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#length\n",
    "w = open('emp.csv')\n",
    "read = csv.reader(w)\n",
    "slice = list(read)\n",
    "print(len(slice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571a59c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jerin', 'thomas', '20000', '30000', '400000', '50000', '60000']\n"
     ]
    }
   ],
   "source": [
    "#append\n",
    "w = open('emp.csv')\n",
    "read = csv.reader(w)\n",
    "slic = list(read)\n",
    "new_list = ['jerin','thomas']\n",
    "for i in slic[1:]:\n",
    "    new_list.append(i[3])\n",
    "print(new_list)\n",
    "    \n",
    "    \n",
    "#w= open('1.csv')\n",
    "#read=csv.reader(w)\n",
    "#slicing=list(read)\n",
    "#emp_list=['yamini','ashish']\n",
    "#for i in slicing[1:]:\n",
    " #   emp_list.append(i[3])\n",
    "#print(emp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open('emp.csv')\n",
    "read=csv.reader(w)\n",
    "sli=list(read)\n",
    "full_name=[]\n",
    "for i in sli[1:6]:\n",
    "    full_name.append(i[0]+' '+i[1])\n",
    "print(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e547b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing pdf file\n",
    "with open('3.csv','w')as w:          #check the pwd file is there or not\n",
    "    x=csv.writer(w)\n",
    "    x.writerows([['pyhton','java','R'],['apple','banana','coconut'],['biriyani','dosa','idli']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c395cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2Note: you may need to restart the kernel to use updated packages.\n",
      "  Using cached PyPDF2-1.26.0.tar.gz (77 kB)\n",
      "Building wheels for collected packages: PyPDF2\n",
      "  Building wheel for PyPDF2 (setup.py): started\n",
      "\n",
      "  Building wheel for PyPDF2 (setup.py): finished with status 'done'\n",
      "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-py3-none-any.whl size=61101 sha256=9b36dbb80c39401b8dc47f42c1282784fa98195bbc714855aac72248089dd68c\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\d9\\dc\\ec\\72da68331f30074b9950c1737c23cb8a67484e61498bc9713d\n",
      "Successfully built PyPDF2\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-1.26.0\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c919df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5380a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading pdf \n",
    "with open('WBP.pdf','rb')as pdf_handle:\n",
    "    pdf_reader=PyPDF2.PdfFileReader(pdf_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339956c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#finding number of pages in pdf\n",
    "with open('WBP.pdf','rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "    page_num = pdf_reader.numPages\n",
    "    print(page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7483f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competencies. Dramatically mesh low-risk high-yield alignments before \n",
      "transparent e-tailers. \n",
      "Appropriately empower dynamic leadership skills after business portals. \n",
      "Globally myocardinate interactive supply chains with distinctive quality \n",
      "vectors. Globally revolutionize global sources through interoperable \n",
      "services. Enthusiastically mesh long-term high-impact infrastructures vis-a-vis \n",
      "efÞcient customer service. Professionally fashion wireless leadership rather \n",
      "than prospective experiences. Energistically myocardinate clicks-and-\n",
      "mortar testing procedures whereas next-generation manufactured \n",
      "products. \n",
      "Dynamically reinvent market-driven opportunities and ubiquitous \n",
      "interfaces. Energistically fabricate an expanded array of niche markets \n",
      "through robust products. Appropriately implement visionary e-services vis-\n",
      "a-vis strategic web-readiness. \n",
      "Compellingly embrace empowered e-business after user friendly \n",
      "intellectual capital. Interactively actualize front-end processes with \n",
      "effective convergence. Synergistically deliver performance based \n",
      "methods of empowerment whereas distributed expertise. \n",
      "EfÞciently enable enabled sources and cost effective products. \n",
      "Completely synthesize principle-centered information after ethical \n",
      "communities. EfÞciently innovate open-source infrastructures via \n",
      "inexpensive materials. Objectively integrate enterprise-wide strategic theme areas with \n",
      "functionalized infrastructures. Interactively productize premium \n",
      "technologies whereas interdependent quality vectors. Rapaciously utilize \n",
      "enterprise experiences via 24/7 markets. Uniquely matrix economically sound value through cooperative \n",
      "technology. Competently parallel task fully researched data and enterprise \n",
      "process improvements. Collaboratively expedite quality manufactured \n",
      "products via client-focused results. \n",
      "BUSINESS PROPOSAL\n",
      "!4\n"
     ]
    }
   ],
   "source": [
    "#extracting text from pdf\n",
    "with open('WBP.pdf','rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "    page_one = pdf_reader.getPage(3)\n",
    "    extract_text = page_one.extractText()\n",
    "    print(extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdcf5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying one pages and appending to new one\n",
    "with open('WBP.pdf','rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "    page_one = pdf_reader.getPage(1)\n",
    "    pdf_writer = PyPDF2.PdfFileWriter()\n",
    "    pdf_writer.addPage(page_one)\n",
    "    pdf_output = open('new.pdf','wb')\n",
    "    pdf_writer.write(pdf_output)\n",
    "    pdf_output.close()\n",
    "                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2552d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applications. Quickly drive clicks-and-mortar catalysts for change before \n",
      "vertical architectures. \n",
      "Credibly reintermediate backend ideas for cross-platform models. \n",
      "Continually reintermediate integrated processes through technically sound \n",
      "intellectual capital. Holistically foster superior methodologies without \n",
      "market-driven best practices. Distinctively exploit optimal alignments for intuitive bandwidth. Quickly \n",
      "coordinate e-business applications through revolutionary catalysts for \n",
      "change. Seamlessly underwhelm optimal testing procedures whereas \n",
      "bricks-and-clicks processes. \n",
      "Synergistically evolve 2.0 technologies rather than just in time initiatives. \n",
      "Quickly deploy strategic networks with compelling e-business. Credibly \n",
      "pontiÞcate highly efÞcient manufactured products and enabled data. \n",
      "Dynamically target high-payoff intellectual capital for customized \n",
      "technologies. Objectively integrate emerging core competencies before \n",
      "process-centric communities. Dramatically evisculate holistic innovation \n",
      "rather than client-centric data. Progressively maintain extensive infomediaries via extensible niches. \n",
      "Dramatically disseminate standardized metrics after resource-leveling \n",
      "processes. Objectively pursue diverse catalysts for change for \n",
      "interoperable meta-services. \n",
      "Proactively fabricate one-to-one materials via effective e-business. \n",
      "Completely synergize scalable e-commerce rather than high standards in \n",
      "e-services. Assertively iterate resource maximizing products after leading-\n",
      "edge intellectual capital. Distinctively re-engineer revolutionary meta-services and premium \n",
      "architectures. Intrinsically incubate intuitive opportunities and real-time \n",
      "potentialities. Appropriately communicate one-to-one technology after \n",
      "plug-and-play networks. Quickly aggregate B2B users and worldwide potentialities. Progressively \n",
      "plagiarize resource-leveling e-commerce through resource-leveling core \n",
      "BUSINESS PROPOSAL\n",
      "!3\n"
     ]
    }
   ],
   "source": [
    "#copying all pages and appending on new one\n",
    "with open('WBP.PDF','rb') as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "    text = []\n",
    "    for i in range(pdf_reader.numPages):\n",
    "        page = pdf_reader.getPage(i)\n",
    "        text.append(page.extractText())\n",
    "    print(text[2])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ea0aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applications. Quickly drive clicks-and-mortar catalysts for change before \n",
      "vertical architectures. \n",
      "Credibly reintermediate backend ideas for cross-platform models. \n",
      "Continually reintermediate integrated processes through technically sound \n",
      "intellectual capital. Holistically foster superior methodologies without \n",
      "market-driven best practices. Distinctively exploit optimal alignments for intuitive bandwidth. Quickly \n",
      "coordinate e-business applications through revolutionary catalysts for \n",
      "change. Seamlessly underwhelm optimal testing procedures whereas \n",
      "bricks-and-clicks processes. \n",
      "Synergistically evolve 2.0 technologies rather than just in time initiatives. \n",
      "Quickly deploy strategic networks with compelling e-business. Credibly \n",
      "pontiÞcate highly efÞcient manufactured products and enabled data. \n",
      "Dynamically target high-payoff intellectual capital for customized \n",
      "technologies. Objectively integrate emerging core competencies before \n",
      "process-centric communities. Dramatically evisculate holistic innovation \n",
      "rather than client-centric data. Progressively maintain extensive infomediaries via extensible niches. \n",
      "Dramatically disseminate standardized metrics after resource-leveling \n",
      "processes. Objectively pursue diverse catalysts for change for \n",
      "interoperable meta-services. \n",
      "Proactively fabricate one-to-one materials via effective e-business. \n",
      "Completely synergize scalable e-commerce rather than high standards in \n",
      "e-services. Assertively iterate resource maximizing products after leading-\n",
      "edge intellectual capital. Distinctively re-engineer revolutionary meta-services and premium \n",
      "architectures. Intrinsically incubate intuitive opportunities and real-time \n",
      "potentialities. Appropriately communicate one-to-one technology after \n",
      "plug-and-play networks. Quickly aggregate B2B users and worldwide potentialities. Progressively \n",
      "plagiarize resource-leveling e-commerce through resource-leveling core \n",
      "BUSINESS PROPOSAL\n",
      "!3\n"
     ]
    }
   ],
   "source": [
    "with open('WBP.pdf','rb')as pdf_handle:\n",
    "    pdf_reader=PyPDF2.PdfFileReader(pdf_handle)\n",
    "    text = []\n",
    "    for i in range(pdf_reader.numPages):\n",
    "        page = pdf_reader.getPage(i)    \n",
    "        text.append(page.extractText())\n",
    "    # print(text)#prin all text\n",
    "    print(text[2])#perticular page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
